import time
from langchain.callbacks.base import BaseCallbackHandler

class StreamlitCallbackHandler(BaseCallbackHandler):
    """Handler pour afficher le texte en streaming dans Streamlit"""
    
    def __init__(self, placeholder, update_every=3, delay=0.15):
        self.placeholder = placeholder
        self.text = ""
        self.counter = 0
        self.update_every = update_every
        self.delay = delay
    
    def on_llm_new_token(self, token, **kwargs):
        self.text += token
        self.counter += 1
        if self.counter % self.update_every == 1:
            self.placeholder.markdown(self.text + "â–Œ")
            time.sleep(self.delay)
    
    def on_llm_end(self, *args, **kwargs):
        self.placeholder.markdown(self.text)

class RetrievalCallbackHandler(BaseCallbackHandler):
    """Handler pour afficher les chunks rÃ©cupÃ©rÃ©s dans la console"""
    
    def __init__(self, memory=None):
        self.memory = memory
        self.original_question = None
    
    def on_retriever_start(self, serialized, query, **kwargs):
        # Stocker la question originale pour comparaison
        self.original_question = query
        
        print(f"\nğŸ” RECHERCHE DE CHUNKS pour la question: '{query}'")
        print("=" * 80)
        
        # Afficher la mÃ©moire de conversation si disponible
        if self.memory and hasattr(self.memory, 'memory') and hasattr(self.memory.memory, 'chat_memory'):
            chat_memory = self.memory.memory.chat_memory
            messages = chat_memory.messages
            
            if messages:
                print(f"\nğŸ’¬ MÃ‰MOIRE DE CONVERSATION ({len(messages)} messages):")
                print("=" * 80)
                for i, msg in enumerate(messages, 1):
                    role = "ğŸ‘¤ Utilisateur" if msg.type == "human" else "ğŸ¤– Assistant"
                    print(f"\n{i}. {role}:")
                    print("-" * 40)
                    print(msg.content)
                    print("-" * 40)
                    print(f"ğŸ“Š Longueur: {len(msg.content)} caractÃ¨res")
                print("=" * 80)
            else:
                print("\nğŸ’¬ MÃ‰MOIRE DE CONVERSATION: (vide)")
        else:
            print("\nğŸ’¬ MÃ‰MOIRE DE CONVERSATION: (non disponible)")
    
    def on_retriever_end(self, documents, **kwargs):
        print(f"ğŸ“„ {len(documents)} chunks rÃ©cupÃ©rÃ©s:")
        print("-" * 80)
        for i, doc in enumerate(documents, 1):
            print(f"\nğŸ“„ Chunk {i}:")
            print(f"   Source: {getattr(doc.metadata, 'source', 'N/A')}")
            print(f"   Page: {getattr(doc.metadata, 'page', 'N/A')}")
            print(f"   Contenu: {doc.page_content[:200]}...")
            if len(doc.page_content) > 200:
                print(f"   (tronquÃ©, longueur totale: {len(doc.page_content)} caractÃ¨res)")
            print("-" * 40)
        print("=" * 80)
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        """Affiche le prompt utilisÃ© par le systÃ¨me"""
        print(f"\nğŸ¤– PROMPT UTILISÃ‰ PAR LE SYSTÃˆME:")
        print("=" * 80)
        
        # Chercher le prompt dans les inputs
        prompt_text = ""
        
        # Essayer diffÃ©rentes faÃ§ons de rÃ©cupÃ©rer le prompt
        if "question" in inputs:
            question = inputs["question"]
            # Si c'est une chaÃ®ne simple
            if isinstance(question, str):
                prompt_text = question
            # Si c'est une liste de messages (format chat)
            elif isinstance(question, list) and len(question) > 0:
                # Prendre le dernier message de l'utilisateur
                last_message = question[-1]
                if hasattr(last_message, 'content'):
                    prompt_text = last_message.content
                elif isinstance(last_message, dict) and 'content' in last_message:
                    prompt_text = last_message['content']
        
        # Si on n'a pas trouvÃ© dans "question", chercher dans d'autres clÃ©s possibles
        if not prompt_text:
            for key in ["input", "query", "text", "prompt"]:
                if key in inputs:
                    value = inputs[key]
                    if isinstance(value, str):
                        prompt_text = value
                        break
                    elif isinstance(value, list) and len(value) > 0:
                        last_item = value[-1]
                        if hasattr(last_item, 'content'):
                            prompt_text = last_item.content
                            break
                        elif isinstance(last_item, dict) and 'content' in last_item:
                            prompt_text = last_item['content']
                            break
        
        # VÃ©rifier si la question a Ã©tÃ© reformulÃ©e
        if self.original_question and prompt_text and prompt_text != self.original_question:
            print(f"âš ï¸  ATTENTION: Question reformulÃ©e!")
            print(f"   Question originale: '{self.original_question}'")
            print(f"   Question reformulÃ©e: '{prompt_text}'")
            print("-" * 40)
        
        # Afficher les 500 premiers caractÃ¨res
        if prompt_text:
            truncated_prompt = prompt_text[:500]
            print(f"ğŸ“ Question utilisateur (500 premiers caractÃ¨res):")
            print("-" * 40)
            print(truncated_prompt)
            if len(prompt_text) > 500:
                print(f"... (tronquÃ©, longueur totale: {len(prompt_text)} caractÃ¨res)")
            print("-" * 40)
        else:
            print("âŒ Impossible de rÃ©cupÃ©rer le prompt")
            print("ğŸ” ClÃ©s disponibles dans inputs:", list(inputs.keys()) if inputs else "Aucune")
        
        print("=" * 80)
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """Affiche le prompt systÃ¨me complet utilisÃ© par le LLM"""
        print(f"\nğŸ¤– PROMPT SYSTÃˆME COMPLET UTILISÃ‰ PAR LE LLM:")
        print("=" * 80)
        
        if prompts and len(prompts) > 0:
            # Le premier prompt contient gÃ©nÃ©ralement le prompt systÃ¨me complet
            system_prompt = prompts[0]
            
            # Afficher les 1000 premiers caractÃ¨res du prompt systÃ¨me
            truncated_system = system_prompt[:1000]
            print(f"ğŸ“ Prompt systÃ¨me (1000 premiers caractÃ¨res):")
            print("-" * 40)
            print(truncated_system)
            if len(system_prompt) > 1000:
                print(f"... (tronquÃ©, longueur totale: {len(system_prompt)} caractÃ¨res)")
            print("-" * 40)
            
            # Si il y a plusieurs prompts, afficher le nombre
            if len(prompts) > 1:
                print(f"ğŸ“Š Nombre total de prompts: {len(prompts)}")
        else:
            print("âŒ Aucun prompt systÃ¨me trouvÃ©")
        
        print("=" * 80) 